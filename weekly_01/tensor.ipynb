{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量是深度学习和科学计算中一个核心概念。为了帮助普通用户理解张量及其重要性，我们可以从以下几个方面进行知识普及。\n",
    "\n",
    "## 什么是张量？\n",
    "\n",
    "1. **多维数组**: 张量可以被看作是一个多维数组，用于存储和操作各种类型的数据。它是标量、向量和矩阵的推广。标量是0维张量，向量是一维张量，矩阵是二维张量，而三维及以上的则称为高阶张量[1][2][3]。\n",
    "\n",
    "2. **数据容器**: 张量就像一个容器，可以存储不同类型的数据，如数字、图像、音频等。例如，图像可以表示为一个二维或三维的张量，其中包含像素值和颜色信息[1]。\n",
    "\n",
    "3. **几何对象**: 在数学上，张量也可以被视为一种不随着坐标系变化而改变的几何对象。这种特性使得它在物理学和工程学中也有广泛应用[2][3]。\n",
    "\n",
    "## 为什么需要张量？\n",
    "\n",
    "1. **数据处理的基础**: 在深度学习中，模型需要处理大量的数据。张量提供了一种统一的方式来表示和操作这些数据，无论数据是简单的数字还是复杂的多媒体内容[1]。\n",
    "\n",
    "2. **支持复杂运算**: 张量运算是深度学习的核心之一。通过对张量进行加法、乘法、卷积等操作，可以提取数据特征、进行数据转换等。这些运算对于训练神经网络至关重要[1]。\n",
    "\n",
    "3. **灵活性和扩展性**: 张量支持广播机制，可以在不同形状的张量之间进行运算，自动扩展维度以适应计算需求。这种灵活性大大简化了编程工作[1]。\n",
    "\n",
    "4. **高效计算**: 现代硬件（如GPU）擅长处理大规模并行计算，而张量运算能够充分利用这些硬件资源，提高计算效率。\n",
    "\n",
    "## 张量在实际应用中的例子\n",
    "\n",
    "- **图像处理**: 图像通常表示为三维张量（高度×宽度×颜色通道），如RGB图像。\n",
    "- **音频分析**: 音频信号可以表示为一维张量，其中包含时间序列数据。\n",
    "- **自然语言处理**: 文本数据可以被转换为二维或三维张量，以便输入到语言模型中进行处理。\n",
    "\n",
    "总之，张量作为一种强大的工具，在深度学习和数据科学中扮演着不可或缺的角色。通过理解和掌握张量的概念和操作，我们能够更好地进行数据分析和模型构建，从而推动人工智能技术的发展。\n",
    "\n",
    "Citations:\n",
    "[1] https://cloud.baidu.com/article/2795259\n",
    "[2] https://blog.csdn.net/weixin_49883619/article/details/109735335\n",
    "[3] https://blog.csdn.net/qq_36793268/article/details/107375314"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标量、向量、矩阵和张量是数学和计算中用于表示数据的基本结构，它们之间有着层级关系，并在深度学习中扮演着重要角色。下面是对它们之间关系的解释，以及它们在大语言模型中的应用。\n",
    "\n",
    "## 标量、向量、矩阵、张量之间的关系\n",
    "\n",
    "1. **标量 (Scalar)**:\n",
    "\n",
    "   - 标量是一个单独的数值，没有方向性。可以被视为 0 阶张量。\n",
    "   - 例子：$$a = 5$$\n",
    "\n",
    "2. **向量 (Vector)**:\n",
    "\n",
    "   - 向量是一组有序排列的数，具有大小和方向。可以被视为一阶张量。\n",
    "   - 例子：$$\\mathbf{v} = [1, 2, 3]$$\n",
    "\n",
    "3. **矩阵 (Matrix)**:\n",
    "\n",
    "   - 矩阵是二维数组，由多个向量组成。可以被视为二阶张量。\n",
    "   - 例子：$$\\mathbf{M} = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}$$\n",
    "\n",
    "4. **张量 (Tensor)**:\n",
    "   - 张量是更高维度的数组，可以有三维、四维甚至更高维度。三维以上的张量用于表示复杂的数据结构。\n",
    "   - 例子：三维张量可以表示为$$\\mathbf{T} = [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]$$\n",
    "\n",
    "## 张量在大语言模型中的应用\n",
    "\n",
    "- **数据表示**: 在大语言模型（如 GPT-2）中，文本数据通常被转换为张量形式，以便进行计算和处理。输入文本被分割成 token，每个 token 通过嵌入矩阵转换为向量，这些向量组合成一个三维张量。\n",
    "\n",
    "- **向量化**: 向量化是指将数据转换为向量或张量形式，以便进行高效计算。在大语言模型中，向量化使得模型能够快速处理和分析大量文本数据。\n",
    "\n",
    "- **高维数据处理**: 大语言模型需要处理复杂的多维数据，张量提供了一种灵活而高效的方式来表示这些数据，并支持并行计算以加速训练和推理过程。\n",
    "\n",
    "## 更高维度的张量\n",
    "\n",
    "- 张量可以扩展到任意维度，具体取决于应用需求。在深度学习中，高维张量常用于表示批次数据、时间序列或多通道图像等复杂结构。\n",
    "- 高维张量通过其灵活性和强大的表达能力，在处理复杂的数据模式和关系时尤为重要。\n",
    "\n",
    "总之，标量、向量、矩阵和张量构成了从简单到复杂的数据表示体系。在大语言模型中，张量作为核心数据结构，支持了从输入处理到模型训练的各个环节。通过理解这些概念，我们能够更好地理解和应用深度学习技术。\n",
    "\n",
    "Citations:\n",
    "[1] https://blog.csdn.net/sinat_29957455/article/details/117396685\n",
    "[2] https://www.cnblogs.com/smoka-ai/p/14459113.html\n",
    "[3] https://developer.aliyun.com/article/1086801\n",
    "[4] https://blog.csdn.net/sinat_37322535/article/details/131303317\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量是数学和物理学中用于表示多维数据的基本结构，能够有效地表示真实世界中的复杂关系；与大模型关系的可以进一步学习以下内容：\n",
    "\n",
    "- 大语言模型中的，Token, 向量化，预测逻辑\n",
    "- Transformers 模型架构中张量的利用\n",
    "- 在张量的并行计算中 高性能GPU的价值 （ 矩阵乘法、卷积）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在学习 PyTorch 中的张量操作基础时，以下是一些关键的学习重点和步骤。这些内容将帮助您理解和掌握 PyTorch 张量的基本使用。\n",
    "\n",
    "## PyTorch 张量操作基础学习重点\n",
    "\n",
    "### 1. **张量的创建**\n",
    "\n",
    "- **直接从数据创建**:\n",
    "\n",
    "  ```python\n",
    "  import torch\n",
    "  data = [[1, 2], [3, 4]]\n",
    "  x_data = torch.tensor(data)\n",
    "  ```\n",
    "\n",
    "- **从 NumPy 数组创建**:\n",
    "\n",
    "  ```python\n",
    "  import numpy as np\n",
    "  np_array = np.array(data)\n",
    "  x_np = torch.from_numpy(np_array)\n",
    "  ```\n",
    "\n",
    "- **使用工厂方法创建**:\n",
    "  - 创建空张量（未初始化）：\n",
    "    ```python\n",
    "    x_empty = torch.empty(3, 4)\n",
    "    ```\n",
    "  - 创建全零或全一张量：\n",
    "    ```python\n",
    "    x_zeros = torch.zeros(2, 3)\n",
    "    x_ones = torch.ones(2, 3)\n",
    "    ```\n",
    "  - 创建随机数张量：\n",
    "    ```python\n",
    "    x_rand = torch.rand(2, 3)\n",
    "    ```\n",
    "\n",
    "### 2. **张量的数据类型**\n",
    "\n",
    "- PyTorch 支持多种数据类型，如`float32`、`int64`等。可以在创建张量时指定数据类型：\n",
    "  ```python\n",
    "  x_float = torch.tensor([1.0, 2.0], dtype=torch.float32)\n",
    "  ```\n",
    "\n",
    "### 3. **张量的基本操作**\n",
    "\n",
    "- **算术运算**:\n",
    "\n",
    "  - 张量与标量的运算：\n",
    "    ```python\n",
    "    x = torch.ones(2, 2)\n",
    "    y = x + 1\n",
    "    ```\n",
    "  - 张量与张量的运算（逐元素）：\n",
    "    ```python\n",
    "    a = torch.rand(2, 3)\n",
    "    b = torch.rand(2, 3)\n",
    "    c = a + b\n",
    "    ```\n",
    "\n",
    "- **矩阵运算**:\n",
    "  - 矩阵乘法：\n",
    "    ```python\n",
    "    a = torch.rand(2, 3)\n",
    "    b = torch.rand(3, 2)\n",
    "    c = a @ b\n",
    "    ```\n",
    "\n",
    "### 4. **张量的形状操作**\n",
    "\n",
    "- **查看和改变形状**:\n",
    "\n",
    "  - 查看形状：\n",
    "    ```python\n",
    "    shape = x.shape\n",
    "    ```\n",
    "  - 改变形状（不改变数据）：\n",
    "    ```python\n",
    "    x_reshaped = x.view(6, -1) # 自动计算第二维度大小\n",
    "    ```\n",
    "\n",
    "- **转置和维度变换**:\n",
    "  - 转置：\n",
    "    ```python\n",
    "    x_transposed = x.t()\n",
    "    ```\n",
    "\n",
    "### 学习重点总结\n",
    "\n",
    "- 理解如何使用不同的方法创建和初始化张量。\n",
    "- 掌握基本的张量运算，包括算术运算和矩阵乘法。\n",
    "- 熟悉如何查看和改变张量的形状，以及如何进行转置。\n",
    "- 理解数据类型的作用，并在创建张量时正确指定。\n",
    "\n",
    "通过掌握这些基础知识，您将能够在 PyTorch 中有效地进行各种深度学习任务中的数据处理和模型构建。\n",
    "\n",
    "Citations:\n",
    "[1] https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html\n",
    "[2] https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html\n",
    "[3] https://www.kdnuggets.com/2018/05/pytorch-tensor-basics.html\n",
    "[4] https://www.codementor.io/@packt/how-to-perform-basic-operations-in-pytorch-code-10al39a4c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# 直接从数据创建张量\n",
    "\n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# 从Numpy数组创建张量\n",
    "import numpy as np\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个空张量\n",
    "x_empty = torch.empty(3, 4)\n",
    "\n",
    "print(x_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_zeros:  tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "--------\n",
      "x_ones:  tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 创建全零或全一张量\n",
    "x_zeros = torch.zeros(2, 3)\n",
    "x_ones = torch.ones(2, 3)\n",
    "\n",
    "print(\"x_zeros: \", x_zeros)\n",
    "print(\"--------\")\n",
    "print(\"x_ones: \", x_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3927, 0.2174, 0.5256],\n",
      "        [0.9097, 0.0564, 0.5663]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个随机张量\n",
    "\n",
    "x_rand = torch.rand(2, 3)\n",
    "\n",
    "print(x_rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 张量的数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2.])\n",
      "--------------\n",
      "tensor([1, 2])\n"
     ]
    }
   ],
   "source": [
    "# float32\n",
    "x_float = torch.tensor([1.0, 2.0], dtype=torch.float32)\n",
    "\n",
    "print(x_float)\n",
    "\n",
    "print(\"--------------\")\n",
    "\n",
    "x_int = torch.tensor([1, 2], dtype=torch.int64)\n",
    "\n",
    "print(x_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 张量的基本操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2.],\n",
      "        [2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# 张量与标量的运算\n",
    "x = torch.ones(2, 2)\n",
    "y = x + 1\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6486, 1.7093, 1.8027],\n",
      "        [1.4754, 0.8034, 0.2204]])\n"
     ]
    }
   ],
   "source": [
    "# 张量与张量的运算\n",
    "a = torch.rand(2, 3)\n",
    "b = torch.rand(2, 3)\n",
    "c = a + b\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5791, 0.4614],\n",
      "        [1.1767, 1.0641]])\n"
     ]
    }
   ],
   "source": [
    "# 矩阵乘法\n",
    "a = torch.rand(2, 3)\n",
    "b = torch.rand(3, 2)\n",
    "c = a @ b\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 张量的形状操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# 查看形状\n",
    "shape = x.shape\n",
    "\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([2, 2])\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "# 改变形状\n",
    "x = torch.ones((2, 2))\n",
    "print(\"Original shape:\", x.shape)\n",
    "\n",
    "x_reshaped = x.view(4, -1)  # 自动计算第二维度大小\n",
    "\n",
    "print(x_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 张量的转置和维度变换\n",
    "x_transposed = x.t()\n",
    "\n",
    "print(x_transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "Shape: torch.Size([2, 3])\n",
      "\n",
      "Reshaped tensor to (3, 2):\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "Shape: torch.Size([3, 2])\n",
      "\n",
      "Transposed tensor:\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "Shape: torch.Size([3, 2])\n",
      "\n",
      "Tensor after unsqueeze (add dimension at position 0):\n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]]])\n",
      "Shape: torch.Size([1, 2, 3])\n",
      "\n",
      "Tensor after squeeze (remove dimensions of size 1):\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "Shape: torch.Size([2, 3])\n",
      "\n",
      "Expanded tensor to shape (2, 3, 4):\n",
      "tensor([[[1, 1, 1, 1],\n",
      "         [2, 2, 2, 2],\n",
      "         [3, 3, 3, 3]],\n",
      "\n",
      "        [[4, 4, 4, 4],\n",
      "         [5, 5, 5, 5],\n",
      "         [6, 6, 6, 6]]])\n",
      "Shape: torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# 关于张量的维度转置示例\n",
    "import torch\n",
    "\n",
    "# 创建一个形状为 (2, 3) 的张量\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"Original tensor:\")\n",
    "print(x)\n",
    "print(\"Shape:\", x.shape)\n",
    "\n",
    "# 改变形状: 使用 view 改变张量形状为 (3, 2)\n",
    "x_reshaped = x.view(3, 2)\n",
    "print(\"\\nReshaped tensor to (3, 2):\")\n",
    "print(x_reshaped)\n",
    "print(\"Shape:\", x_reshaped.shape)\n",
    "\n",
    "# 转置: 使用 t() 方法对二维张量进行转置\n",
    "x_transposed = x.t()\n",
    "print(\"\\nTransposed tensor:\")\n",
    "print(x_transposed)\n",
    "print(\"Shape:\", x_transposed.shape)\n",
    "\n",
    "# 增加维度: 使用 unsqueeze 增加一个维度\n",
    "x_unsqueezed = x.unsqueeze(0)  # 在第0维增加一个维度\n",
    "print(\"\\nTensor after unsqueeze (add dimension at position 0):\")\n",
    "print(x_unsqueezed)\n",
    "print(\"Shape:\", x_unsqueezed.shape)\n",
    "\n",
    "# 压缩维度: 使用 squeeze 去除大小为1的维度\n",
    "x_squeezed = x_unsqueezed.squeeze()\n",
    "print(\"\\nTensor after squeeze (remove dimensions of size 1):\")\n",
    "print(x_squeezed)\n",
    "print(\"Shape:\", x_squeezed.shape)\n",
    "\n",
    "# 扩展张量: 使用 expand 或 expand_as 来匹配目标形状\n",
    "x_expanded = x.unsqueeze(2).expand(2, 3, 4)  # 扩展到形状 (2, 3, 4)\n",
    "print(\"\\nExpanded tensor to shape (2, 3, 4):\")\n",
    "print(x_expanded)\n",
    "print(\"Shape:\", x_expanded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tensor:\n",
      "tensor([[[[1., 2., 3., 0., 1.],\n",
      "          [0., 1., 2., 3., 0.],\n",
      "          [1., 0., 1., 2., 3.],\n",
      "          [0., 1., 0., 1., 2.],\n",
      "          [3., 0., 1., 2., 1.]]]])\n",
      "\n",
      "Initial Kernel Weights:\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.3167, -0.2501,  0.2888],\n",
      "          [-0.1965, -0.0475,  0.3118],\n",
      "          [-0.0816,  0.3066,  0.1001]]]], requires_grad=True)\n",
      "\n",
      "Output Tensor after Convolution:\n",
      "tensor([[[[1.4469, 1.2031, 1.7044],\n",
      "          [0.9188, 1.4469, 1.2031],\n",
      "          [0.5826, 1.1190, 2.0601]]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 如何进行张量的卷积操作 （CNN)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 创建一个示例输入张量，形状为 (batch_size, channels, height, width)\n",
    "# 这里我们假设有一个批量大小为1的单通道图像，大小为5x5\n",
    "input_tensor = torch.tensor([[[[1, 2, 3, 0, 1],\n",
    "                               [0, 1, 2, 3, 0],\n",
    "                               [1, 0, 1, 2, 3],\n",
    "                               [0, 1, 0, 1, 2],\n",
    "                               [3, 0, 1, 2, 1]]]], dtype=torch.float32)\n",
    "\n",
    "print(\"Input Tensor:\")\n",
    "print(input_tensor)\n",
    "\n",
    "# 定义一个二维卷积层\n",
    "# 输入通道数为1，输出通道数为1，卷积核大小为3x3\n",
    "conv_layer = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3)\n",
    "\n",
    "# 查看卷积核的权重（初始化的）\n",
    "print(\"\\nInitial Kernel Weights:\")\n",
    "print(conv_layer.weight)\n",
    "\n",
    "# 执行卷积操作\n",
    "output_tensor = conv_layer(input_tensor)\n",
    "\n",
    "print(\"\\nOutput Tensor after Convolution:\")\n",
    "print(output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下面介绍一些将更好理解的资源转为张量的方法\n",
    "\n",
    "通过将我们熟悉的资源转化为张量的示例，有助于我们理解如何张量的作用，重点可以关注转化的过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "0.18.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "print(torch.__version__)\n",
    "print(torchtext.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将一段文本转化为张量\n",
    "\n",
    "要将一段文本转换为张量，通常需要将文本首先进行数值化处理，例如通过词嵌入技术将文本中的每个词或字符转换为向量。下面是如何使用PyTorch和`torchtext`库将文本转换为张量的一个示例。\n",
    "\n",
    "1. **安装必要的库**:\n",
    "   - 确保安装了`torch`和`torchtext`库。\n",
    "\n",
    "2. **定义词汇表和嵌入**:\n",
    "   - 使用预定义的词汇表和嵌入矩阵（如GloVe或Word2Vec）来将每个单词转换为向量。\n",
    "\n",
    "3. **处理文本**:\n",
    "   - 将文本分割为单词，并利用词汇表将其转换为索引。\n",
    "   - 使用嵌入层将索引转换为张量。\n",
    "\n",
    "### 代码说明\n",
    "\n",
    "- **Tokenizer**: 使用`torchtext.data.utils.get_tokenizer()`来分割文本。\n",
    "- **GloVe Embeddings**: 使用预训练的GloVe模型，将每个单词映射到一个50维的向量。\n",
    "- **Token to Tensor**: 将每个token转换为其对应的GloVe向量，并使用`torch.stack()`将这些向量组合成一个张量。\n",
    "\n",
    "### 关键点\n",
    "\n",
    "- **词嵌入**: 通过预训练的嵌入模型（如GloVe、Word2Vec）可以有效地将文本表示为数值化形式。\n",
    "- **张量表示**: 转换后的张量可以直接用于深度学习模型中进行训练或推理。\n",
    "- **灵活性**: 可以根据需要选择不同维度和大小的预训练嵌入模型，以适应不同的应用场景。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ai_dev/lib/python3.10/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ai_dev/lib/python3.10/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ai_dev/lib/python3.10/site-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      ".vector_cache/glove.6B.zip: 862MB [02:39, 5.39MB/s]                               \n",
      "100%|█████████▉| 399999/400000 [00:04<00:00, 84777.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['this', 'is', 'an', 'example', 'sentence', 'for', 'conversion', '.']\n",
      "Text Tensor Shape: torch.Size([8, 50])\n",
      "Text Tensor: tensor([[ 5.3074e-01,  4.0117e-01, -4.0785e-01,  1.5444e-01,  4.7782e-01,\n",
      "          2.0754e-01, -2.6951e-01, -3.4023e-01, -1.0879e-01,  1.0563e-01,\n",
      "         -1.0289e-01,  1.0849e-01, -4.9681e-01, -2.5128e-01,  8.4025e-01,\n",
      "          3.8949e-01,  3.2284e-01, -2.2797e-01, -4.4342e-01, -3.1649e-01,\n",
      "         -1.2406e-01, -2.8170e-01,  1.9467e-01,  5.5513e-02,  5.6705e-01,\n",
      "         -1.7419e+00, -9.1145e-01,  2.7036e-01,  4.1927e-01,  2.0279e-02,\n",
      "          4.0405e+00, -2.4943e-01, -2.0416e-01, -6.2762e-01, -5.4783e-02,\n",
      "         -2.6883e-01,  1.8444e-01,  1.8204e-01, -2.3536e-01, -1.6155e-01,\n",
      "         -2.7655e-01,  3.5506e-02, -3.8211e-01, -7.5134e-04, -2.4822e-01,\n",
      "          2.8164e-01,  1.2819e-01,  2.8762e-01,  1.4440e-01,  2.3611e-01],\n",
      "        [ 6.1850e-01,  6.4254e-01, -4.6552e-01,  3.7570e-01,  7.4838e-01,\n",
      "          5.3739e-01,  2.2239e-03, -6.0577e-01,  2.6408e-01,  1.1703e-01,\n",
      "          4.3722e-01,  2.0092e-01, -5.7859e-02, -3.4589e-01,  2.1664e-01,\n",
      "          5.8573e-01,  5.3919e-01,  6.9490e-01, -1.5618e-01,  5.5830e-02,\n",
      "         -6.0515e-01, -2.8997e-01, -2.5594e-02,  5.5593e-01,  2.5356e-01,\n",
      "         -1.9612e+00, -5.1381e-01,  6.9096e-01,  6.6246e-02, -5.4224e-02,\n",
      "          3.7871e+00, -7.7403e-01, -1.2689e-01, -5.1465e-01,  6.6705e-02,\n",
      "         -3.2933e-01,  1.3483e-01,  1.9049e-01,  1.3812e-01, -2.1503e-01,\n",
      "         -1.6573e-02,  3.1200e-01, -3.3189e-01, -2.6001e-02, -3.8203e-01,\n",
      "          1.9403e-01, -1.2466e-01, -2.7557e-01,  3.0899e-01,  4.8497e-01],\n",
      "        [ 3.6143e-01,  5.8615e-01, -2.3718e-01,  7.9656e-02,  8.0192e-01,\n",
      "          4.9919e-01, -3.3172e-01, -1.9785e-01,  1.3876e-01,  1.6804e-01,\n",
      "          1.2557e-01, -2.4494e-01, -9.2315e-02,  3.5135e-01, -2.4396e-02,\n",
      "         -3.1713e-01,  7.1206e-02,  3.7087e-01, -8.2027e-01,  2.1193e-01,\n",
      "         -5.2153e-02,  2.9928e-01, -4.9494e-01, -1.2546e-01, -1.2394e-02,\n",
      "         -2.2174e+00, -8.2666e-02,  1.5184e-01,  5.0396e-02,  6.1229e-01,\n",
      "          3.7305e+00, -9.3152e-01, -2.8716e-01, -4.8056e-01,  6.0682e-02,\n",
      "          5.8104e-02,  4.2065e-01, -4.6598e-02,  8.3503e-02, -2.3819e-01,\n",
      "          3.8828e-01,  3.6926e-01, -4.4066e-01,  7.5673e-02, -5.0556e-02,\n",
      "         -4.2269e-01, -2.1577e-01,  3.9362e-01,  3.6523e-01,  3.6077e-01],\n",
      "        [ 5.1564e-01,  5.6912e-01, -1.9759e-01,  8.0456e-03,  4.1697e-01,\n",
      "          5.9502e-01, -5.3312e-02, -8.3222e-01, -2.1715e-01,  3.1045e-01,\n",
      "          9.3520e-02,  3.5323e-01,  2.8151e-01, -3.5308e-01,  2.3496e-01,\n",
      "          4.4290e-02,  1.7109e-02,  6.3749e-03, -1.6620e-02, -6.9576e-01,\n",
      "          1.9819e-02, -5.2746e-01, -1.4011e-01,  2.1962e-01,  1.3692e-01,\n",
      "         -1.2683e+00, -8.9416e-01, -1.8310e-01,  2.3343e-01, -5.8254e-02,\n",
      "          3.2481e+00, -4.8794e-01, -1.2070e-02, -8.1645e-01,  2.1182e-01,\n",
      "         -1.7837e-01, -2.8740e-02,  9.9358e-02, -1.4944e-01,  2.6010e-01,\n",
      "          1.8919e-01,  1.5022e-01,  1.8278e-01,  5.0052e-01, -2.5532e-02,\n",
      "          2.4671e-01,  1.0596e-01,  1.3612e-01,  9.0427e-03,  3.9962e-01],\n",
      "        [-4.7255e-01,  2.2225e-01, -6.3452e-01, -7.6602e-01,  1.0656e+00,\n",
      "          7.6451e-01,  1.6131e+00,  8.7044e-01,  1.7932e-01,  1.0780e+00,\n",
      "         -5.5141e-01, -2.2577e-01, -2.2832e-01, -4.0384e-01,  1.7432e+00,\n",
      "         -7.8039e-01, -8.9178e-01, -5.0943e-01,  3.3377e-01,  3.9782e-01,\n",
      "          1.6417e-01,  2.2198e-01, -6.1903e-02, -4.0991e-03, -6.1842e-01,\n",
      "         -2.7304e+00,  8.8745e-01,  4.5329e-02,  2.2605e-01,  3.5428e-01,\n",
      "          1.9750e+00, -1.4989e+00, -7.2365e-01,  9.6346e-02,  1.2030e+00,\n",
      "         -3.8698e-01,  1.0918e+00, -1.8933e-01, -1.5378e-01, -2.2674e-01,\n",
      "         -6.3325e-01,  8.0934e-01,  3.6922e-01,  8.1327e-01, -4.6229e-01,\n",
      "         -1.0106e+00,  4.2674e-01,  3.7537e-01,  6.7690e-02,  1.3591e-01],\n",
      "        [ 1.5272e-01,  3.6181e-01, -2.2168e-01,  6.6051e-02,  1.3029e-01,\n",
      "          3.7075e-01, -7.5874e-01, -4.4722e-01,  2.2563e-01,  1.0208e-01,\n",
      "          5.4225e-02,  1.3494e-01, -4.3052e-01, -2.1340e-01,  5.6139e-01,\n",
      "         -2.1445e-01,  7.7974e-02,  1.0137e-01, -5.1306e-01, -4.0295e-01,\n",
      "          4.0639e-01,  2.3309e-01,  2.0696e-01, -1.2668e-01, -5.0634e-01,\n",
      "         -1.7131e+00,  7.7183e-02, -3.9138e-01, -1.0594e-01, -2.3743e-01,\n",
      "          3.9552e+00,  6.6596e-01, -6.1841e-01, -3.2680e-01,  3.7021e-01,\n",
      "          2.5764e-01,  3.8977e-01,  2.7121e-01,  4.3024e-02, -3.4322e-01,\n",
      "          2.0339e-02,  2.1420e-01,  4.4097e-02,  1.4003e-01, -2.0079e-01,\n",
      "          7.4794e-02, -3.6076e-01,  4.3382e-01, -8.4617e-02,  1.2140e-01],\n",
      "        [ 2.6282e-01, -3.5292e-01, -1.5368e-01, -8.0432e-01, -5.7699e-02,\n",
      "          6.3253e-01, -2.7319e-01, -5.1681e-01,  2.3305e-01,  1.1693e+00,\n",
      "          6.0664e-01,  3.8622e-01, -5.9344e-02, -4.8120e-01, -2.9171e-01,\n",
      "          4.4495e-01,  3.6402e-01, -9.4441e-01, -6.8486e-01,  3.7206e-01,\n",
      "          4.8615e-01, -5.4886e-01, -1.0588e+00, -2.8101e-01,  8.3789e-03,\n",
      "         -5.8455e-01,  9.3590e-01, -9.4972e-01,  7.8938e-01,  2.4237e-01,\n",
      "          2.1803e+00, -3.4406e-01, -6.2696e-01, -1.6726e-02,  7.6966e-01,\n",
      "          2.0987e-01,  9.1589e-01,  1.8938e-01,  1.3587e-01,  6.2152e-01,\n",
      "          7.3002e-01, -9.8246e-02, -2.4122e-01,  9.1277e-02,  3.1963e-02,\n",
      "          4.9521e-01,  7.9001e-01,  2.9685e-01,  1.7086e-01, -5.1799e-03],\n",
      "        [ 1.5164e-01,  3.0177e-01, -1.6763e-01,  1.7684e-01,  3.1719e-01,\n",
      "          3.3973e-01, -4.3478e-01, -3.1086e-01, -4.4999e-01, -2.9486e-01,\n",
      "          1.6608e-01,  1.1963e-01, -4.1328e-01, -4.2353e-01,  5.9868e-01,\n",
      "          2.8825e-01, -1.1547e-01, -4.1848e-02, -6.7989e-01, -2.5063e-01,\n",
      "          1.8472e-01,  8.6876e-02,  4.6582e-01,  1.5035e-02,  4.3474e-02,\n",
      "         -1.4671e+00, -3.0384e-01, -2.3441e-02,  3.0589e-01, -2.1785e-01,\n",
      "          3.7460e+00,  4.2284e-03, -1.8436e-01, -4.6209e-01,  9.8329e-02,\n",
      "         -1.1907e-01,  2.3919e-01,  1.1610e-01,  4.1705e-01,  5.6763e-02,\n",
      "         -6.3681e-05,  6.8987e-02,  8.7939e-02, -1.0285e-01, -1.3931e-01,\n",
      "          2.2314e-01, -8.0803e-02, -3.5652e-01,  1.6413e-02,  1.0216e-01]])\n"
     ]
    }
   ],
   "source": [
    "# 将一段文本转化为张量\n",
    "import torch\n",
    "from torchtext.vocab import GloVe\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "# 定义tokenizer\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# 加载预训练的GloVe词向量\n",
    "glove = GloVe(name='6B', dim=50)  # 使用50维的GloVe向量\n",
    "\n",
    "# 示例文本\n",
    "text = \"This is an example sentence for conversion.\"\n",
    "\n",
    "# 将文本分割为单词并获取索引\n",
    "tokens = tokenizer(text)\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# 将tokens转换为对应的GloVe向量\n",
    "vectors = [glove[token] for token in tokens]\n",
    "\n",
    "# 转换为张量\n",
    "text_tensor = torch.stack(vectors)\n",
    "print(\"Text Tensor Shape:\", text_tensor.shape)\n",
    "print(\"Text Tensor:\", text_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图片转换为张量\n",
    "\n",
    "一张图片转换为PyTorch张量可以使用`torchvision`库中的`transforms.ToTensor()`功能。以下是具体步骤和代码示例：\n",
    "\n",
    "## 步骤\n",
    "\n",
    "1. **导入必要的库**:\n",
    "   - 需要导入`torch`、`torchvision.transforms`和`PIL.Image`。\n",
    "\n",
    "2. **读取图片**:\n",
    "   - 使用PIL库打开图片文件。\n",
    "\n",
    "3. **定义转换操作**:\n",
    "   - 使用`transforms.ToTensor()`将图片转换为张量。\n",
    "\n",
    "4. **执行转换**:\n",
    "   - 应用定义的转换操作，将图片数据转换为PyTorch张量。\n",
    "\n",
    "### 代码说明\n",
    "\n",
    "- **PIL Image**: 使用PIL库的`Image.open()`方法读取图像文件，生成一个PIL图像对象。\n",
    "- **ToTensor()**: `transforms.ToTensor()`会将PIL图像或NumPy数组转换为PyTorch张量，并自动将像素值归一化到[0, 1]之间。\n",
    "- **张量形状**: 转换后的张量通常是三维的，形状为(C, H, W)，其中C是颜色通道数（如RGB图像的3），H是高度，W是宽度。\n",
    "\n",
    "这种方法简化了从图像到张量的转换过程，使得图像数据可以被直接输入到深度学习模型中进行训练或推理。\n",
    "\n",
    "Citations:\n",
    "[1] https://www.projectpro.io/recipes/convert-image-tensor-pytorch\n",
    "[2] https://www.tutorialspoint.com/how-to-convert-an-image-to-a-pytorch-tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Tensor:\n",
      "tensor([[[0.0039, 0.0039, 0.0039,  ..., 0.1216, 0.1216, 0.1294],\n",
      "         [0.0039, 0.0039, 0.0039,  ..., 0.1294, 0.1333, 0.1333],\n",
      "         [0.0039, 0.0039, 0.0039,  ..., 0.1333, 0.1333, 0.1373],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0196, 0.0196, 0.0196],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0196, 0.0196, 0.0157],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0196, 0.0196, 0.0157]],\n",
      "\n",
      "        [[0.0196, 0.0196, 0.0196,  ..., 0.0196, 0.0196, 0.0196],\n",
      "         [0.0196, 0.0196, 0.0196,  ..., 0.0196, 0.0196, 0.0196],\n",
      "         [0.0196, 0.0196, 0.0196,  ..., 0.0196, 0.0196, 0.0196],\n",
      "         ...,\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.1020, 0.1020, 0.0980],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.1020, 0.0980, 0.0980],\n",
      "         [0.0157, 0.0157, 0.0157,  ..., 0.1020, 0.0980, 0.0980]],\n",
      "\n",
      "        [[0.0667, 0.0667, 0.0667,  ..., 0.7922, 0.8000, 0.8000],\n",
      "         [0.0667, 0.0667, 0.0667,  ..., 0.8118, 0.8118, 0.8000],\n",
      "         [0.0667, 0.0667, 0.0667,  ..., 0.8157, 0.8157, 0.8196],\n",
      "         ...,\n",
      "         [0.0510, 0.0510, 0.0510,  ..., 0.5098, 0.5098, 0.5059],\n",
      "         [0.0510, 0.0510, 0.0510,  ..., 0.5098, 0.5020, 0.4941],\n",
      "         [0.0510, 0.0510, 0.0510,  ..., 0.5098, 0.5020, 0.4941]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]])\n"
     ]
    }
   ],
   "source": [
    "# 将图片转为张量\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# 读取图片\n",
    "image_path = 'sample.png'  # 请替换为你的图片路径\n",
    "img = Image.open(image_path)\n",
    "\n",
    "# 定义转换操作\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# 将图片转换为张量\n",
    "img_tensor = transform(img)\n",
    "\n",
    "# 打印转换后的张量\n",
    "print(\"Image Tensor:\")\n",
    "print(img_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
